# LiteLLM Configuration Bundle
# Note: The master_key in general_settings references the LITELLM_MASTER_KEY env var
# which is loaded from llm-secrets Secret in the deployment.
# The OpenAI API key is also loaded from the secret via environment variable.
kind: Bundle
apiVersion: fleet.cattle.io/v1alpha1
metadata:
  name: litellm-config
spec:
  resources:
  - content: |-
      ---
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: litellm-config
        namespace: default
      data:
        config.yaml: |
          model_list:
            - model_name: ollama/tinyllama
              litellm_params:
                model: ollama/tinyllama
                api_base: http://ollama.default.svc.cluster.local
            - model_name: openai/gpt-3.5-turbo
              litellm_params:
                model: gpt-3.5-turbo
                # API key is loaded from OPENAI_API_KEY environment variable
                api_key: os.environ/OPENAI_API_KEY
          litellm_settings:
            drop_params: false
            debug: false
            default_model: ollama/tinyllama
          general_settings:
            authentication:
              # Master key is loaded from LITELLM_MASTER_KEY environment variable
              master_key: os.environ/LITELLM_MASTER_KEY
    name: litellm-config.yaml
  targets:
  - clusterSelector:
      matchExpressions:
      - key: clusterclass-name.fleet.addons.cluster.x-k8s.io
        operator: In
        values:
        - docker-llm-clusterclass