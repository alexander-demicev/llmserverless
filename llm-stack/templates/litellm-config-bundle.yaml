kind: Bundle
apiVersion: fleet.cattle.io/v1alpha1
metadata:
  name: litellm-config
spec:
  resources:
  - content: |-
      ---
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: litellm-config
        namespace: default
      data:
        config.yaml: |
          model_list:
            - model_name: ollama/tinyllama
              litellm_params:
                model: ollama/tinyllama
                api_base: http://ollama.default.svc.cluster.local
            - model_name: openai/gpt-3.5-turbo
              litellm_params:
                model: gpt-3.5-turbo
                api_key: sk-xxx-your-openai-key-here
          litellm_settings:
            drop_params: false
            debug: true
            default_model: ollama/tinyllama
          general_settings:
            authentication:
              master_key: "test-master-key"
    name: litellm-config.yaml
  targets:
  - clusterSelector:
      matchExpressions:
      - key: clusterclass-name.fleet.addons.cluster.x-k8s.io
        operator: In
        values:
        - docker-llm-clusterclass
#      - model_name: ollama/llama3
#        litellm_params:
#          model: ollama/llama3
#          api_base: http://ollama.default.svc.cluster.local